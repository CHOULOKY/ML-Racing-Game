{
    "name": "root",
    "gauges": {
        "RaceToGoal.Policy.Entropy.mean": {
            "value": 0.45579832792282104,
            "min": 0.4453491270542145,
            "max": 0.8634903430938721,
            "count": 50
        },
        "RaceToGoal.Policy.Entropy.sum": {
            "value": 4609.03271484375,
            "min": 4400.04931640625,
            "max": 8752.337890625,
            "count": 50
        },
        "RaceToGoal.Step.mean": {
            "value": 499986.0,
            "min": 9983.0,
            "max": 499986.0,
            "count": 50
        },
        "RaceToGoal.Step.sum": {
            "value": 499986.0,
            "min": 9983.0,
            "max": 499986.0,
            "count": 50
        },
        "RaceToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": 9.22061824798584,
            "min": 0.3473142087459564,
            "max": 9.539713859558105,
            "count": 50
        },
        "RaceToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": 1447.6370849609375,
            "min": 54.5283317565918,
            "max": 1507.2747802734375,
            "count": 50
        },
        "RaceToGoal.Environment.EpisodeLength.mean": {
            "value": 4747.0,
            "min": 574.0,
            "max": 6365.0,
            "count": 43
        },
        "RaceToGoal.Environment.EpisodeLength.sum": {
            "value": 4747.0,
            "min": 574.0,
            "max": 19259.0,
            "count": 43
        },
        "RaceToGoal.Environment.CumulativeReward.mean": {
            "value": 450.85000014305115,
            "min": -50.26324991136789,
            "max": 451.611854493618,
            "count": 43
        },
        "RaceToGoal.Environment.CumulativeReward.sum": {
            "value": 450.85000014305115,
            "min": -125.7171425782144,
            "max": 1806.447417974472,
            "count": 43
        },
        "RaceToGoal.Policy.ExtrinsicReward.mean": {
            "value": 450.85000014305115,
            "min": -50.26324991136789,
            "max": 451.611854493618,
            "count": 43
        },
        "RaceToGoal.Policy.ExtrinsicReward.sum": {
            "value": 450.85000014305115,
            "min": -125.7171425782144,
            "max": 1806.447417974472,
            "count": 43
        },
        "RaceToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 50
        },
        "RaceToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 50
        },
        "RaceToGoal.Losses.PolicyLoss.mean": {
            "value": 0.05110572988245015,
            "min": 0.04241488047215777,
            "max": 0.055662367423065004,
            "count": 48
        },
        "RaceToGoal.Losses.PolicyLoss.sum": {
            "value": 0.05110572988245015,
            "min": 0.04241488047215777,
            "max": 0.055662367423065004,
            "count": 48
        },
        "RaceToGoal.Losses.ValueLoss.mean": {
            "value": 0.7529999901851018,
            "min": 0.5814192588130633,
            "max": 3.4496974617242815,
            "count": 48
        },
        "RaceToGoal.Losses.ValueLoss.sum": {
            "value": 0.7529999901851018,
            "min": 0.5814192588130633,
            "max": 3.4496974617242815,
            "count": 48
        },
        "RaceToGoal.Policy.LearningRate.mean": {
            "value": 4.1628986123999995e-06,
            "min": 4.1628986123999995e-06,
            "max": 0.0002938182020605999,
            "count": 48
        },
        "RaceToGoal.Policy.LearningRate.sum": {
            "value": 4.1628986123999995e-06,
            "min": 4.1628986123999995e-06,
            "max": 0.0002938182020605999,
            "count": 48
        },
        "RaceToGoal.Policy.Epsilon.mean": {
            "value": 0.10138760000000001,
            "min": 0.10138760000000001,
            "max": 0.19793940000000007,
            "count": 48
        },
        "RaceToGoal.Policy.Epsilon.sum": {
            "value": 0.10138760000000001,
            "min": 0.10138760000000001,
            "max": 0.19793940000000007,
            "count": 48
        },
        "RaceToGoal.Policy.Beta.mean": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000002,
            "count": 48
        },
        "RaceToGoal.Policy.Beta.sum": {
            "value": 0.0005000000000000002,
            "min": 0.0005000000000000002,
            "max": 0.0005000000000000002,
            "count": 48
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1730641883",
        "python_version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Git\\ML-Racing-Game\\venv\\Scripts\\mlagents-learn config/RaceToGoal6.yaml --initialize-from=RaceToGoal5 --run-id=RaceToGoal6 --force",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.0+cpu",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1730642660"
    },
    "total": 776.8857646999822,
    "count": 1,
    "self": 0.016622900002403185,
    "children": {
        "run_training.setup": {
            "total": 0.07873380000819452,
            "count": 1,
            "self": 0.07873380000819452
        },
        "TrainerController.start_learning": {
            "total": 776.7904079999716,
            "count": 1,
            "self": 1.5890270968084224,
            "children": {
                "TrainerController._reset_env": {
                    "total": 38.73038120000274,
                    "count": 1,
                    "self": 38.73038120000274
                },
                "TrainerController.advance": {
                    "total": 736.2862746031606,
                    "count": 62545,
                    "self": 1.4109825120249297,
                    "children": {
                        "env_step": {
                            "total": 552.6517166953709,
                            "count": 62545,
                            "self": 403.8946238933422,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 147.74338380701374,
                                    "count": 62545,
                                    "self": 4.397328806575388,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 143.34605500043835,
                                            "count": 62545,
                                            "self": 143.34605500043835
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.0137089950148948,
                                    "count": 62545,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 737.4614967001253,
                                            "count": 62545,
                                            "is_parallel": true,
                                            "self": 424.59944399932283,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00043929999810643494,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00016840003081597388,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00027089996729046106,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00027089996729046106
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 312.86161340080434,
                                                    "count": 62545,
                                                    "is_parallel": true,
                                                    "self": 8.802144999644952,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 12.004630101117073,
                                                            "count": 62545,
                                                            "is_parallel": true,
                                                            "self": 12.004630101117073
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 265.0206427994708,
                                                            "count": 62545,
                                                            "is_parallel": true,
                                                            "self": 265.0206427994708
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 27.034195500571514,
                                                            "count": 62545,
                                                            "is_parallel": true,
                                                            "self": 11.970950303715654,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 15.06324519685586,
                                                                    "count": 250180,
                                                                    "is_parallel": true,
                                                                    "self": 15.06324519685586
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 182.22357539576478,
                            "count": 62545,
                            "self": 2.1768863956385758,
                            "children": {
                                "process_trajectory": {
                                    "total": 44.22789420018671,
                                    "count": 62545,
                                    "self": 44.092794700176455,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.13509950001025572,
                                            "count": 1,
                                            "self": 0.13509950001025572
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 135.8187947999395,
                                    "count": 48,
                                    "self": 64.195719800191,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 71.6230749997485,
                                            "count": 5760,
                                            "self": 71.6230749997485
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 3.6999990697950125e-06,
                    "count": 1,
                    "self": 3.6999990697950125e-06
                },
                "TrainerController._save_models": {
                    "total": 0.18472140000085346,
                    "count": 1,
                    "self": 0.054956400010269135,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.12976499999058433,
                            "count": 1,
                            "self": 0.12976499999058433
                        }
                    }
                }
            }
        }
    }
}